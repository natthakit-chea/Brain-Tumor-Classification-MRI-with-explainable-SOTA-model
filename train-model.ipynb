{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f032768-6b48-4fbf-be61-11c71dae8949",
   "metadata": {},
   "source": [
    "# load lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "004c0b88-f002-43ae-98d4-fb915a5a359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import time\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from PIL import Image\n",
    "import logging\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b82a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "#     since = time.time()\n",
    "\n",
    "#     # Create a temporary directory to save training checkpoints\n",
    "#     with TemporaryDirectory() as tempdir:\n",
    "#         best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "    \n",
    "#         torch.save(model.state_dict(), best_model_params_path)\n",
    "#         best_acc = 0.0\n",
    "\n",
    "#         for epoch in range(num_epochs):\n",
    "#             print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "#             print('-' * 10)\n",
    "\n",
    "#             # Each epoch has a training and validation phase\n",
    "#             for phase in ['train', 'val']:\n",
    "#                 if phase == 'train':\n",
    "#                     model.train()  # Set model to training mode\n",
    "#                 else:\n",
    "#                     model.eval()   # Set model to evaluate mode\n",
    "\n",
    "#                 running_loss = 0.0\n",
    "#                 running_corrects = 0\n",
    "\n",
    "#                 # Iterate over data.\n",
    "#                 for inputs, labels in dataloaders[phase]:\n",
    "#                     inputs = inputs.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # zero the parameter gradients\n",
    "#                     optimizer.zero_grad()\n",
    "\n",
    "#                     # forward\n",
    "#                     # track history if only in train\n",
    "#                     with torch.set_grad_enabled(phase == 'train'):\n",
    "#                         outputs = model(inputs)\n",
    "#                         _, preds = torch.max(outputs, 1)\n",
    "#                         loss = criterion(outputs, labels)\n",
    "\n",
    "#                         # backward + optimize only if in training phase\n",
    "#                         if phase == 'train':\n",
    "#                             loss.backward()\n",
    "#                             optimizer.step()\n",
    "\n",
    "#                     # statistics\n",
    "#                     running_loss += loss.item() * inputs.size(0)\n",
    "#                     running_corrects += torch.sum(preds == labels.data)\n",
    "#                 if phase == 'train':\n",
    "#                     scheduler.step()\n",
    "\n",
    "#                 epoch_loss = running_loss / dataset_sizes[phase]\n",
    "#                 epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "#                 print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "#                 # deep copy the model\n",
    "#                 if phase == 'val' and epoch_acc > best_acc:\n",
    "#                     best_acc = epoch_acc\n",
    "#                     torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "#             print()\n",
    "\n",
    "#         time_elapsed = time.time() - since\n",
    "#         print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "#         print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "#         # load best model weights\n",
    "#         model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e798509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            val_loss = None  # Placeholder for validation loss\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                if phase == 'val':\n",
    "                    val_loss = epoch_loss  # Store validation loss for scheduler\n",
    "\n",
    "                    # deep copy the model\n",
    "                    if epoch_acc > best_acc:\n",
    "                        best_acc = epoch_acc\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            # Update the learning rate for ReduceLROnPlateau\n",
    "            if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(val_loss)\n",
    "            elif phase == 'train':\n",
    "                scheduler.step()  # Standard step for other schedulers\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "        # Load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c1c18-20e6-4f0c-9906-aff9faec325b",
   "metadata": {},
   "source": [
    "# RESNET50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378400c0-d5fa-4bfe-a1b0-76fa9e8ea4c6",
   "metadata": {},
   "source": [
    "## load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebf65034-ce56-48db-908f-21b5b7ea7a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load the ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)  # Replace the last layer with the number of classes\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9b2ed-595e-4887-8718-16e1bf01c634",
   "metadata": {},
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44e7e216-a422-4ebd-8996-3d311f3c9425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.2613 Acc: 0.9083\n",
      "val Loss: 0.1235 Acc: 0.9475\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.1120 Acc: 0.9606\n",
      "val Loss: 0.0925 Acc: 0.9618\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0722 Acc: 0.9767\n",
      "val Loss: 0.0479 Acc: 0.9828\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0474 Acc: 0.9858\n",
      "val Loss: 0.0318 Acc: 0.9914\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0486 Acc: 0.9860\n",
      "val Loss: 0.0305 Acc: 0.9895\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0387 Acc: 0.9883\n",
      "val Loss: 0.0294 Acc: 0.9895\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0319 Acc: 0.9893\n",
      "val Loss: 0.0274 Acc: 0.9924\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0340 Acc: 0.9891\n",
      "val Loss: 0.0503 Acc: 0.9847\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0223 Acc: 0.9930\n",
      "val Loss: 0.0238 Acc: 0.9933\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0165 Acc: 0.9954\n",
      "val Loss: 0.0188 Acc: 0.9933\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9909\n",
      "val Loss: 0.0285 Acc: 0.9924\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0285 Acc: 0.9905\n",
      "val Loss: 0.0552 Acc: 0.9828\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0239 Acc: 0.9923\n",
      "val Loss: 0.0264 Acc: 0.9924\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0178 Acc: 0.9954\n",
      "val Loss: 0.0234 Acc: 0.9952\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0310 Acc: 0.9907\n",
      "val Loss: 0.0191 Acc: 0.9924\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9919\n",
      "val Loss: 0.0329 Acc: 0.9885\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0145 Acc: 0.9958\n",
      "val Loss: 0.0145 Acc: 0.9962\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0050 Acc: 0.9991\n",
      "val Loss: 0.0104 Acc: 0.9971\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0035 Acc: 0.9993\n",
      "val Loss: 0.0082 Acc: 0.9971\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0046 Acc: 0.9986\n",
      "val Loss: 0.0098 Acc: 0.9962\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0045 Acc: 0.9986\n",
      "val Loss: 0.0119 Acc: 0.9952\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0038 Acc: 0.9988\n",
      "val Loss: 0.0097 Acc: 0.9971\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0030 Acc: 0.9995\n",
      "val Loss: 0.0093 Acc: 0.9971\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0038 Acc: 0.9988\n",
      "val Loss: 0.0164 Acc: 0.9952\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0035 Acc: 0.9989\n",
      "val Loss: 0.0091 Acc: 0.9962\n",
      "\n",
      "Training complete in 4m 41s\n",
      "Best val Acc: 0.9971\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay) \n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "\n",
    "# Load data\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/home/natthakit/304proj/pre_dataset'\n",
    "image_datasets = {x: ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model, criterion, optimizer, scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf4bf1-1942-4ed2-a987-0fcdc80010c4",
   "metadata": {},
   "source": [
    "## save entire model and model's state_dict\n",
    "> #### ***[!TIP ]*** \n",
    "> * Saving entire model: Keeps the architecture, making loading easier but might break across different PyTorch versions.\n",
    "> * Saving state dict: Preferred for flexibility and compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa2cb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf 'saved/crop_resnet50_state_dict.pth'\n",
    "!rm -rf 'saved/crop_resnet50_full_model.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23b1e8f4-a563-4530-bfd3-fa4c88737cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "torch.save(trained_model, 'saved/pre_resnet50_full_model.pth')\n",
    "\n",
    "# Save only the model's state_dict (recommended)\n",
    "torch.save(trained_model.state_dict(), 'saved/pre_resnet50_state_dict.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697fdcfd-0c9d-419b-a463-09eb1375aa09",
   "metadata": {},
   "source": [
    "# SWINV2_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab950f6-495c-4cbb-9b22-6cd5fa4072c8",
   "metadata": {},
   "source": [
    "## load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "787bd219-e7b4-4083-be2b-cc14593f1ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/swin_v2_s-637d8ceb.pth\" to /home/natthakit/.cache/torch/hub/checkpoints/swin_v2_s-637d8ceb.pth\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 191M/191M [00:12<00:00, 16.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.swin_v2_s(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model.head.in_features\n",
    "model.head = nn.Linear(num_ftrs, 4)  # Replace the last layer with the number of classes\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b45555d-d2ba-499c-9186-796371094770",
   "metadata": {},
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f2b35fd-5be4-44e7-aba8-c8c13a7e915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.5863 Acc: 0.7730\n",
      "val Loss: 0.3265 Acc: 0.8827\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.3330 Acc: 0.8743\n",
      "val Loss: 0.1675 Acc: 0.9307\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2551 Acc: 0.9037\n",
      "val Loss: 0.1992 Acc: 0.9322\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2068 Acc: 0.9230\n",
      "val Loss: 0.1482 Acc: 0.9566\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1888 Acc: 0.9291\n",
      "val Loss: 0.0961 Acc: 0.9596\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1659 Acc: 0.9380\n",
      "val Loss: 0.1060 Acc: 0.9566\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1554 Acc: 0.9424\n",
      "val Loss: 0.0815 Acc: 0.9711\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1225 Acc: 0.9561\n",
      "val Loss: 0.0659 Acc: 0.9772\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1180 Acc: 0.9589\n",
      "val Loss: 0.0623 Acc: 0.9802\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1151 Acc: 0.9561\n",
      "val Loss: 0.0611 Acc: 0.9772\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1132 Acc: 0.9576\n",
      "val Loss: 0.0614 Acc: 0.9794\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1071 Acc: 0.9601\n",
      "val Loss: 0.0564 Acc: 0.9810\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1139 Acc: 0.9575\n",
      "val Loss: 0.0572 Acc: 0.9832\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1062 Acc: 0.9585\n",
      "val Loss: 0.0545 Acc: 0.9832\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1064 Acc: 0.9613\n",
      "val Loss: 0.0548 Acc: 0.9817\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1047 Acc: 0.9638\n",
      "val Loss: 0.0548 Acc: 0.9825\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1060 Acc: 0.9610\n",
      "val Loss: 0.0546 Acc: 0.9832\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1035 Acc: 0.9622\n",
      "val Loss: 0.0547 Acc: 0.9825\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1055 Acc: 0.9610\n",
      "val Loss: 0.0541 Acc: 0.9825\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1083 Acc: 0.9592\n",
      "val Loss: 0.0536 Acc: 0.9832\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1075 Acc: 0.9610\n",
      "val Loss: 0.0535 Acc: 0.9825\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1015 Acc: 0.9604\n",
      "val Loss: 0.0535 Acc: 0.9825\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1036 Acc: 0.9601\n",
      "val Loss: 0.0534 Acc: 0.9825\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0966 Acc: 0.9618\n",
      "val Loss: 0.0534 Acc: 0.9825\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1047 Acc: 0.9639\n",
      "val Loss: 0.0533 Acc: 0.9825\n",
      "\n",
      "Training complete in 18m 59s\n",
      "Best val Acc: 0.983244\n"
     ]
    }
   ],
   "source": [
    "# Define criterion, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Load data\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "data_dir = '/home/natthakit/304proj/dataset'\n",
    "image_datasets = {x: ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model, criterion, optimizer, scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556fbd9-e14a-4b9b-b1c4-d89c003c3517",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fdcd209-efe4-495c-b2fe-af1ac980cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "torch.save(trained_model, 'saved/swinv2_s_full_model.pth')\n",
    "\n",
    "# Save only the model's state_dict (recommended)\n",
    "torch.save(trained_model.state_dict(), 'saved/swinv2_s_state_dict.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb58a3f-99a0-4f06-9b44-7b0bd5365570",
   "metadata": {},
   "source": [
    "# MaxVit_T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924d2f9-3e88-40f0-9dea-c5eefb340660",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e01bc5be-0a33-48e1-9ecd-eb32bdcaa4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MaxVit model and weights from torchvision\n",
    "from torchvision.models import maxvit_t, MaxVit_T_Weights\n",
    "\n",
    "# Load the MaxVit-T model with pre-trained weights\n",
    "weights = MaxVit_T_Weights.IMAGENET1K_V1\n",
    "model = maxvit_t(weights=weights)\n",
    "\n",
    "# Check the last layer in the classifier to get the number of input features\n",
    "# Typically, this will be the last layer within the classifier's Sequential block\n",
    "num_ftrs = model.classifier[-1].in_features  # Access the final layer in the classifier\n",
    "model.classifier[-1] = nn.Linear(num_ftrs, 4)  # Replace with a new linear layer for 4 classes\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the inference transforms\n",
    "inference_transforms = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54ae7514-8c41-4659-9472-e88f6b453b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[224]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b009bd9c-eda9-4a7e-ade2-34de67ce74f2",
   "metadata": {},
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df160f7c-5a41-4131-9d6f-28630bbf0d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.0996 Acc: 0.9652\n",
      "val Loss: 0.0564 Acc: 0.9825\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.0903 Acc: 0.9659\n",
      "val Loss: 0.0278 Acc: 0.9939\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0956 Acc: 0.9660\n",
      "val Loss: 0.0420 Acc: 0.9863\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0738 Acc: 0.9723\n",
      "val Loss: 0.0308 Acc: 0.9901\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0691 Acc: 0.9743\n",
      "val Loss: 0.0277 Acc: 0.9924\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0806 Acc: 0.9718\n",
      "val Loss: 0.0234 Acc: 0.9939\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0649 Acc: 0.9779\n",
      "val Loss: 0.0336 Acc: 0.9909\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0602 Acc: 0.9783\n",
      "val Loss: 0.0212 Acc: 0.9947\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0428 Acc: 0.9853\n",
      "val Loss: 0.0158 Acc: 0.9970\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0509 Acc: 0.9816\n",
      "val Loss: 0.0163 Acc: 0.9970\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0485 Acc: 0.9825\n",
      "val Loss: 0.0169 Acc: 0.9970\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0437 Acc: 0.9835\n",
      "val Loss: 0.0168 Acc: 0.9962\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0440 Acc: 0.9841\n",
      "val Loss: 0.0171 Acc: 0.9962\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0374 Acc: 0.9856\n",
      "val Loss: 0.0153 Acc: 0.9977\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0360 Acc: 0.9865\n",
      "val Loss: 0.0154 Acc: 0.9977\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0447 Acc: 0.9835\n",
      "val Loss: 0.0151 Acc: 0.9977\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0379 Acc: 0.9872\n",
      "val Loss: 0.0159 Acc: 0.9970\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0367 Acc: 0.9865\n",
      "val Loss: 0.0157 Acc: 0.9970\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0407 Acc: 0.9844\n",
      "val Loss: 0.0151 Acc: 0.9977\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0454 Acc: 0.9846\n",
      "val Loss: 0.0158 Acc: 0.9970\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0387 Acc: 0.9869\n",
      "val Loss: 0.0155 Acc: 0.9977\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0368 Acc: 0.9891\n",
      "val Loss: 0.0157 Acc: 0.9970\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0402 Acc: 0.9879\n",
      "val Loss: 0.0156 Acc: 0.9977\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0379 Acc: 0.9877\n",
      "val Loss: 0.0155 Acc: 0.9977\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0337 Acc: 0.9883\n",
      "val Loss: 0.0157 Acc: 0.9977\n",
      "\n",
      "Training complete in 21m 1s\n",
      "Best val Acc: 0.997715\n"
     ]
    }
   ],
   "source": [
    "# Define criterion, optimizer, and scheduler\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)  # Use Adam optimizer with lr=1e-4\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': inference_transforms,\n",
    "}\n",
    "\n",
    "# Load data as before\n",
    "image_datasets = {x: ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "trained_model = train_model(model, criterion, optimizer, scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75e2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire model\n",
    "model = torch.load('saved/maxvit_T_full_model.pth')\n",
    "model = model.to(device)  # Move to the correct device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3b8ae8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9455\n",
      "val Loss: 0.2393 Acc: 0.9500\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.1180 Acc: 0.9587\n",
      "val Loss: 0.0712 Acc: 0.9500\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.1276 Acc: 0.9550\n",
      "val Loss: 0.0315 Acc: 1.0000\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.1032 Acc: 0.9636\n",
      "val Loss: 0.0510 Acc: 1.0000\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0918 Acc: 0.9709\n",
      "val Loss: 0.0523 Acc: 0.9500\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.1081 Acc: 0.9626\n",
      "val Loss: 0.0258 Acc: 1.0000\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.1002 Acc: 0.9651\n",
      "val Loss: 0.0233 Acc: 1.0000\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0845 Acc: 0.9703\n",
      "val Loss: 0.0262 Acc: 1.0000\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0728 Acc: 0.9740\n",
      "val Loss: 0.0234 Acc: 1.0000\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0652 Acc: 0.9767\n",
      "val Loss: 0.0272 Acc: 1.0000\n",
      "\n",
      "Training complete in 4m 35s\n",
      "Best val Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Define criterion, optimizer, and scheduler\n",
    "data_dir = '/home/natthakit/304proj/Coursera-Content/Brain-MRI/'\n",
    "image_datasets = {x: ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)  # Use Adam optimizer with lr=1e-4\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load data as before\n",
    "image_datasets = {x: ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "trained_model = train_model(model, criterion, optimizer, scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4878316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model, 'saved/new_maxvit_T_full_model.pth')\n",
    "\n",
    "# Save only the model's state_dict (recommended)\n",
    "torch.save(trained_model.state_dict(), 'saved/new_maxvit_T_state_dict.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf6c94-5edc-40bb-b864-7f8565c19bb9",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7e45eff-62ed-4835-a3d9-3a8fa1f8a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model, 'saved/maxvit_T_full_model.pth')\n",
    "\n",
    "# Save only the model's state_dict (recommended)\n",
    "torch.save(trained_model.state_dict(), 'saved/maxvit_T_state_dict.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc9439-d995-46d5-bdba-5890f4273112",
   "metadata": {},
   "source": [
    "# EfficientNet_B0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d7b6e9-fa97-4d7b-80a3-14dc21c493ef",
   "metadata": {},
   "source": [
    "## load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02087d9-ba3a-4fd3-94e3-15368932c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EfficientNet_B0 model with pretrained weights\n",
    "model = models.efficientnet_v2_s(weights='IMAGENET1K_V1')\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 4)  # Replace the last layer with the number of classes\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63b82a-5812-4e54-bd64-88923a08044b",
   "metadata": {},
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b1ffb7-068b-4968-b9ba-6ff25dc8e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criterion, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b5dc15-2db9-442f-af40-1d4997a66a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7969 Acc: 0.7105\n",
      "val Loss: 0.4372 Acc: 0.8417\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.3514 Acc: 0.8734\n",
      "val Loss: 0.2527 Acc: 0.9038\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2577 Acc: 0.9020\n",
      "val Loss: 0.1470 Acc: 0.9508\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2093 Acc: 0.9219\n",
      "val Loss: 0.1064 Acc: 0.9621\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1735 Acc: 0.9377\n",
      "val Loss: 0.0904 Acc: 0.9682\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1591 Acc: 0.9436\n",
      "val Loss: 0.0614 Acc: 0.9811\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1314 Acc: 0.9517\n",
      "val Loss: 0.0513 Acc: 0.9864\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1233 Acc: 0.9552\n",
      "val Loss: 0.0508 Acc: 0.9864\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1214 Acc: 0.9550\n",
      "val Loss: 0.0429 Acc: 0.9917\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1292 Acc: 0.9534\n",
      "val Loss: 0.0423 Acc: 0.9902\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1330 Acc: 0.9524\n",
      "val Loss: 0.0445 Acc: 0.9894\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1299 Acc: 0.9554\n",
      "val Loss: 0.0395 Acc: 0.9894\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1244 Acc: 0.9559\n",
      "val Loss: 0.0387 Acc: 0.9886\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1199 Acc: 0.9571\n",
      "val Loss: 0.0400 Acc: 0.9894\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9571\n",
      "val Loss: 0.0391 Acc: 0.9902\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1163 Acc: 0.9603\n",
      "val Loss: 0.0403 Acc: 0.9902\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1064 Acc: 0.9648\n",
      "val Loss: 0.0392 Acc: 0.9932\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1232 Acc: 0.9562\n",
      "val Loss: 0.0394 Acc: 0.9924\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1198 Acc: 0.9597\n",
      "val Loss: 0.0382 Acc: 0.9917\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1071 Acc: 0.9603\n",
      "val Loss: 0.0369 Acc: 0.9909\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1250 Acc: 0.9557\n",
      "val Loss: 0.0418 Acc: 0.9902\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1194 Acc: 0.9608\n",
      "val Loss: 0.0370 Acc: 0.9909\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1222 Acc: 0.9571\n",
      "val Loss: 0.0383 Acc: 0.9902\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1109 Acc: 0.9583\n",
      "val Loss: 0.0381 Acc: 0.9909\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1184 Acc: 0.9590\n",
      "val Loss: 0.0379 Acc: 0.9909\n",
      "\n",
      "Training complete in 8m 50s\n",
      "Best val Acc: 0.993182\n"
     ]
    }
   ],
   "source": [
    "# Load data with EfficientNet preprocessing transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Set up datasets and dataloaders as before\n",
    "data_dir = '/home/natthakit/304proj/dataset'\n",
    "image_datasets = {x: ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model, criterion, optimizer, scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a3a931-8acb-411e-86f4-a970b1ab4d24",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b8891b-eef0-461a-905d-8d5cf7e3fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model, 'saved/eff_s_full_model.pth')\n",
    "\n",
    "# Save only the model's state_dict (recommended)\n",
    "torch.save(trained_model.state_dict(), 'saved/eff_s_state_dict.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_venv",
   "language": "python",
   "name": "kaggle_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
